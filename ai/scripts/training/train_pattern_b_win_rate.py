#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‘ã‚¿ãƒ¼ãƒ³B: é¨æ‰‹å‹ç‡ã®ã¿ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´

æ¯”è¼ƒå®Ÿé¨“:
- ãƒ‘ã‚¿ãƒ¼ãƒ³Aï¼ˆç¾è¡Œï¼‰: jockey_place_rate_surface_distanceï¼ˆè¤‡å‹ç‡ï¼‰
- ãƒ‘ã‚¿ãƒ¼ãƒ³Bï¼ˆæœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰: jockey_win_rate_surface_distanceï¼ˆå‹ç‡ï¼‰
- ãƒ‘ã‚¿ãƒ¼ãƒ³C: ä¸¡æ–¹ä½¿ç”¨
"""
from google.cloud import bigquery
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.metrics import roc_auc_score
import pickle

PROJECT_ID = "umadata"
DATASET_ID = "keiba_data"

def load_data_from_bigquery():
    """BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    client = bigquery.Client(project=PROJECT_ID)

    print("=" * 100)
    print("ğŸ“Š BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³B: å‹ç‡ã®ã¿ï¼‰...")
    print("=" * 100)

    query = """
    SELECT
        race_id,
        race_date,
        racecourse,
        surface,
        distance,
        going,
        race_class,
        horse_id,
        horse_name,
        finish_position,
        popularity,
        odds,

        -- åŸºæœ¬æƒ…å ±
        horse_number,
        bracket_number,
        sex,
        age,
        horse_weight,
        weight_change,
        days_since_last_race,

        -- é¨æ‰‹æƒ…å ±ï¼ˆå‹ç‡ã‚’ä½¿ç”¨ï¼‰
        jockey_id,
        is_jockey_change,
        jockey_win_rate_surface_distance,  -- â† å¤‰æ›´ç‚¹ï¼šå‹ç‡ã‚’ä½¿ç”¨
        jockey_rides_surface_distance,

        -- è„šè³ªæƒ…å ±
        running_style_last1,
        running_style_mode,
        running_style_mode_win_rate,
        running_style_last1_win_rate,

        -- éå»æˆç¸¾
        finish_pos_best_last5,

        -- æ”¹å–„ç‰ˆã‚¿ã‚¤ãƒ æŒ‡æ•°ï¼ˆpast 1-3ï¼‰
        time_index_zscore_last1_improved,
        time_index_zscore_last2_improved,
        time_index_zscore_last3_improved,

        -- æ”¹å–„ç‰ˆã‚¿ã‚¤ãƒ æŒ‡æ•°é›†ç´„
        time_index_zscore_mean_3_improved,
        time_index_zscore_best_3_improved,
        time_index_zscore_worst_3_improved,
        time_index_zscore_trend_3_improved,

        -- æ”¹å–„ç‰ˆãƒ©ã‚¹ãƒˆ3FæŒ‡æ•°
        last3f_index_zscore_last1_improved,
        last3f_index_zscore_last2_improved,

        -- ä¼‘é¤Šé–¢é€£
        is_after_long_rest,
        is_consecutive_race,
        rest_period_category

    FROM `umadata.keiba_data.all_features_complete_improved`
    WHERE race_date >= '2021-01-01'
        AND finish_position IS NOT NULL
    ORDER BY race_date
    """

    df = client.query(query).to_dataframe()

    # race_dateã‚’æ—¥ä»˜å‹ã«å¤‰æ›
    df['race_date'] = pd.to_datetime(df['race_date'])

    print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
    print(f"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}è¡Œ")
    print(f"   æœŸé–“: {df['race_date'].min()} ~ {df['race_date'].max()}")
    print(f"   ç·ãƒ¬ãƒ¼ã‚¹æ•°: {df['race_id'].nunique():,}ãƒ¬ãƒ¼ã‚¹")

    return df

def prepare_features(df):
    """ç‰¹å¾´é‡ã‚’æº–å‚™"""
    print("\n" + "=" * 100)
    print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³B: å‹ç‡ï¼‰")
    print("=" * 100)

    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    racecourse_map = {'æœ­å¹Œ': 1, 'å‡½é¤¨': 2, 'ç¦å³¶': 3, 'æ–°æ½Ÿ': 4, 'æ±äº¬': 5, 'ä¸­å±±': 6, 'ä¸­äº¬': 7, 'äº¬éƒ½': 8, 'é˜ªç¥': 9, 'å°å€‰': 10}
    surface_map = {'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}
    going_map = {'è‰¯': 0, 'ã‚„ã‚„é‡': 1, 'é‡': 2, 'ä¸è‰¯': 3}
    race_class_map = {'æ–°é¦¬': 0, 'æœªå‹åˆ©': 1, 'ï¼‘å‹ã‚¯ãƒ©ã‚¹': 2, 'ï¼’å‹ã‚¯ãƒ©ã‚¹': 3, 'ï¼“å‹ã‚¯ãƒ©ã‚¹': 4, 'ã‚ªãƒ¼ãƒ—ãƒ³': 5}

    df['racecourse_encoded'] = df['racecourse'].map(racecourse_map).fillna(0)
    df['surface_encoded'] = df['surface'].map(surface_map).fillna(0)
    df['going_encoded'] = df['going'].map(going_map).fillna(0)
    df['race_class_encoded'] = df['race_class'].map(race_class_map).fillna(5)

    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆï¼ˆ32å€‹ - is_debutã‚’å‰Šé™¤ã€å‹ç‡ã‚’ä½¿ç”¨ï¼‰
    features = [
        # è„šè³ªï¼ˆ4å€‹ï¼‰
        'running_style_last1', 'running_style_mode',
        'running_style_mode_win_rate', 'running_style_last1_win_rate',

        # é¨æ‰‹ï¼ˆ3å€‹ï¼‰â† å¤‰æ›´ç‚¹ï¼šwin_rateã‚’ä½¿ç”¨
        'jockey_rides_surface_distance',
        'jockey_win_rate_surface_distance',  # â† å‹ç‡
        'is_jockey_change',

        # é¦¬ã®æˆç¸¾ï¼ˆ1å€‹ï¼‰
        'finish_pos_best_last5',

        # ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ï¼ˆ4å€‹ï¼‰
        'racecourse_encoded', 'surface_encoded', 'going_encoded', 'race_class_encoded',

        # é¦¬ã®åŸºæœ¬æƒ…å ±ï¼ˆ8å€‹ï¼‰
        'distance', 'sex', 'age', 'horse_weight', 'weight_change',
        'bracket_number', 'horse_number', 'days_since_last_race',

        # æ”¹å–„ç‰ˆã‚¿ã‚¤ãƒ æŒ‡æ•°ï¼ˆpast 1-3ã€3å€‹ï¼‰
        'time_index_zscore_last1_improved',
        'time_index_zscore_last2_improved',
        'time_index_zscore_last3_improved',

        # æ”¹å–„ç‰ˆã‚¿ã‚¤ãƒ æŒ‡æ•°é›†ç´„ï¼ˆ4å€‹ï¼‰
        'time_index_zscore_mean_3_improved',
        'time_index_zscore_best_3_improved',
        'time_index_zscore_worst_3_improved',
        'time_index_zscore_trend_3_improved',

        # æ”¹å–„ç‰ˆãƒ©ã‚¹ãƒˆ3FæŒ‡æ•°ï¼ˆ2å€‹ï¼‰
        'last3f_index_zscore_last1_improved',
        'last3f_index_zscore_last2_improved',

        # ä¼‘é¤Šé–¢é€£ï¼ˆ3å€‹ - is_debutã¨is_after_long_restã‚’å‰Šé™¤ï¼‰
        'is_consecutive_race', 'rest_period_category'
    ]

    print(f"\nâœ… ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡: {len(features)}å€‹")
    print(f"\nã€å¤‰æ›´ç‚¹ã€‘")
    print(f"  - é¨æ‰‹çµ±è¨ˆ: jockey_win_rate_surface_distanceï¼ˆå‹ç‡ï¼‰ã‚’ä½¿ç”¨")
    print(f"  - å‰Šé™¤: is_debut, is_after_long_restï¼ˆé‡è¦åº¦0%ï¼‰")

    # æ¬ æå€¤å‡¦ç†
    print(f"\nã€æ¬ æå€¤ã®çŠ¶æ³ã€‘")
    for feat in features:
        null_count = df[feat].isnull().sum()
        null_pct = null_count / len(df) * 100
        if null_pct > 0:
            print(f"  {feat}: {null_count:,}å€‹ ({null_pct:.1f}%)")

    # æ¬ æå€¤ã‚’0ã§åŸ‹ã‚ã‚‹
    X = df[features].fillna(0)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆ1ç€=1, ãã‚Œä»¥å¤–=0ï¼‰
    y = (df['finish_position'] == 1).astype(int)

    print(f"\nâœ… ç‰¹å¾´é‡æº–å‚™å®Œäº†")
    print(f"   1ç€ç‡: {y.mean()*100:.2f}%")

    return X, y, features

def train_and_evaluate(df):
    """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦è©•ä¾¡"""
    print("\n" + "=" * 100)
    print("ğŸš‚ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³B: å‹ç‡ã®ã¿ï¼‰")
    print("=" * 100)

    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆ2024-11-01ã§train/testï¼‰
    train_df = df[df['race_date'] < '2024-11-01'].copy()
    test_df = df[df['race_date'] >= '2024-11-01'].copy()

    print(f"\nã€ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã€‘")
    print(f"  è¨“ç·´æœŸé–“: {train_df['race_date'].min()} ~ {train_df['race_date'].max()}")
    print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_df):,}è¡Œï¼ˆ{train_df['race_id'].nunique():,}ãƒ¬ãƒ¼ã‚¹ï¼‰")
    print(f"  ãƒ†ã‚¹ãƒˆæœŸé–“: {test_df['race_date'].min()} ~ {test_df['race_date'].max()}")
    print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df):,}è¡Œï¼ˆ{test_df['race_id'].nunique():,}ãƒ¬ãƒ¼ã‚¹ï¼‰")

    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæº–å‚™
    X_train, y_train, features = prepare_features(train_df)
    X_test, y_test, _ = prepare_features(test_df)

    # LightGBMãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'seed': 42
    }

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    train_data = lgb.Dataset(X_train, label=y_train)
    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)

    # è¨“ç·´
    print(f"\nğŸƒ è¨“ç·´é–‹å§‹...")
    model = lgb.train(
        params,
        train_data,
        num_boost_round=1000,
        valid_sets=[train_data, test_data],
        valid_names=['train', 'test'],
        callbacks=[
            lgb.early_stopping(stopping_rounds=50),
            lgb.log_evaluation(period=100)
        ]
    )

    print(f"\nâœ… è¨“ç·´å®Œäº†ï¼ˆbest iteration: {model.best_iteration}ï¼‰")

    # äºˆæ¸¬
    y_pred_train = model.predict(X_train, num_iteration=model.best_iteration)
    y_pred_test = model.predict(X_test, num_iteration=model.best_iteration)

    # AUCè©•ä¾¡
    auc_train = roc_auc_score(y_train, y_pred_train)
    auc_test = roc_auc_score(y_test, y_pred_test)

    print("\n" + "=" * 100)
    print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³B: å‹ç‡ï¼‰")
    print("=" * 100)
    print(f"\nã€AUCã€‘")
    print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {auc_train:.4f}")
    print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {auc_test:.4f}")

    # ç‰¹å¾´é‡é‡è¦åº¦
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importance(importance_type='gain')
    }).sort_values('importance', ascending=False)

    print(f"\nã€ç‰¹å¾´é‡é‡è¦åº¦ Top20ã€‘")
    print(feature_importance.head(20).to_string(index=False))

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬çµæœã‚’ä¿å­˜
    test_df['predicted_prob'] = y_pred_test
    test_df['predicted_rank'] = test_df.groupby('race_id')['predicted_prob'].rank(ascending=False, method='first')

    # é©ä¸­ç‡ãƒ»å›åç‡è©•ä¾¡
    evaluate_betting_performance(test_df)

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model.save_model('../../models/model_pattern_b_win_rate.txt')
    with open('../../models/model_pattern_b_win_rate.pkl', 'wb') as f:
        pickle.dump(model, f)

    print(f"\nğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†")
    print(f"   - models/model_pattern_b_win_rate.txt")
    print(f"   - models/model_pattern_b_win_rate.pkl")

    # ç‰¹å¾´é‡é‡è¦åº¦ã‚’CSVä¿å­˜
    feature_importance.to_csv('../../data/evaluations/feature_importance_pattern_b.csv', index=False, encoding='utf-8-sig')
    print(f"   - data/evaluations/feature_importance_pattern_b.csv")

    return model, test_df, feature_importance, auc_test

def evaluate_betting_performance(test_df):
    """çš„ä¸­ç‡ãƒ»å›åç‡ã‚’è©•ä¾¡"""
    print("\n" + "=" * 100)
    print("ğŸ¯ é¦¬åˆ¸ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆäºˆæ¸¬1ä½ã®é¦¬ã‚’å˜å‹è³¼å…¥ï¼‰")
    print("=" * 100)

    # äºˆæ¸¬1ä½ã®é¦¬ã®ã¿æŠ½å‡º
    predicted_winners = test_df[test_df['predicted_rank'] == 1].copy()

    total_races = len(predicted_winners)
    wins = (predicted_winners['finish_position'] == 1).sum()
    win_rate = wins / total_races * 100

    # å›åç‡è¨ˆç®—ï¼ˆ100å††ãƒ™ãƒƒãƒˆï¼‰
    bet_amount = 100
    total_bet = total_races * bet_amount

    # çš„ä¸­æ™‚ã®æ‰•ã„æˆ»ã—
    winning_bets = predicted_winners[predicted_winners['finish_position'] == 1]
    total_return = (winning_bets['odds'] * bet_amount).sum()

    recovery_rate = (total_return / total_bet) * 100

    print(f"\nã€çµæœã€‘")
    print(f"  ç·ãƒ¬ãƒ¼ã‚¹æ•°: {total_races:,}ãƒ¬ãƒ¼ã‚¹")
    print(f"  çš„ä¸­æ•°: {wins}ãƒ¬ãƒ¼ã‚¹")
    print(f"  çš„ä¸­ç‡: {win_rate:.2f}%")
    print(f"  ç·æŠ•è³‡é¡: {total_bet:,}å††")
    print(f"  ç·æ‰•æˆ»é¡: {total_return:,.0f}å††")
    print(f"  å›åç‡: {recovery_rate:.2f}%")
    print(f"  æç›Š: {total_return - total_bet:,.0f}å††")

    # é–¾å€¤0.50ã§ã®è©•ä¾¡
    print(f"\nã€é«˜ä¿¡é ¼åº¦æˆ¦ç•¥ï¼ˆé–¾å€¤0.50ï¼‰ã€‘")
    high_conf = predicted_winners[predicted_winners['predicted_prob'] >= 0.50]
    if len(high_conf) > 0:
        hc_wins = (high_conf['finish_position'] == 1).sum()
        hc_win_rate = hc_wins / len(high_conf) * 100
        hc_total_bet = len(high_conf) * bet_amount
        hc_winning = high_conf[high_conf['finish_position'] == 1]
        hc_return = (hc_winning['odds'] * bet_amount).sum()
        hc_recovery = (hc_return / hc_total_bet) * 100

        print(f"  ãƒ™ãƒƒãƒˆæ•°: {len(high_conf)}ãƒ¬ãƒ¼ã‚¹")
        print(f"  çš„ä¸­ç‡: {hc_win_rate:.2f}%")
        print(f"  å›åç‡: {hc_recovery:.2f}%")
        print(f"  æç›Š: {hc_return - hc_total_bet:,.0f}å††")
    else:
        print(f"  è©²å½“ãƒ¬ãƒ¼ã‚¹ãªã—")

def main():
    print("\n" + "=" * 100)
    print("ğŸ ãƒ‘ã‚¿ãƒ¼ãƒ³B: é¨æ‰‹å‹ç‡ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«è¨“ç·´")
    print("=" * 100)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_data_from_bigquery()

    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ»è©•ä¾¡
    model, test_df, feature_importance, auc_test = train_and_evaluate(df)

    print("\n" + "=" * 100)
    print("âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³Bè¨“ç·´å®Œäº†")
    print(f"   AUC: {auc_test:.4f}")
    print("=" * 100)

if __name__ == '__main__':
    main()
