#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
2025å¹´æœ‰é¦¬è¨˜å¿µã®äºˆæ¸¬ï¼ˆé¨æ‰‹IDç‰ˆï¼‰

arima.txtã‹ã‚‰å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æ”¹å–„ç‰ˆãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
é¨æ‰‹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½¿ã£ã¦æ­£ã—ã„jockey_idã‚’å–å¾—
"""
from google.cloud import bigquery
import pandas as pd
import numpy as np
import pickle
import re

PROJECT_ID = "umadata"
DATASET_ID = "keiba_data"

# é¨æ‰‹åãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆarima.txt â†’ jockeyãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
JOCKEY_MAPPING = {
    'ãƒ«ãƒ¡ãƒ¼ãƒ«': 'C.ãƒ«ãƒ¡ãƒ¼ãƒ«',
    'ï¼£ãƒ‡ãƒ ãƒ¼ãƒ­': 'C.ãƒ‡ãƒ ãƒ¼ãƒ­',
    'Cãƒ‡ãƒ ãƒ¼ãƒ­': 'C.ãƒ‡ãƒ ãƒ¼ãƒ­',
    'ãƒ‡ãƒ ãƒ¼ãƒ­': 'C.ãƒ‡ãƒ ãƒ¼ãƒ­',
    'æ­¦è±Š': 'æ­¦è±Š',
    'å·ç”°': 'å·ç”°å°†é›…',
    'æˆ¸å´åœ­': 'æˆ¸å´åœ­å¤ª',
    'æˆ¸å´': 'æˆ¸å´åœ­å¤ª',
    'å‚äº•': 'å‚äº•ç‘ æ˜Ÿ',
    'å›£é‡': 'å›£é‡å¤§æˆ',
    'è»é‡æ¥µ': 'è»é‡æ¥µ',
    'é®«å³¶é§¿': 'é®«å³¶å…‹é§¿',
    'åŒ—æ‘å‹': 'åŒ—æ‘å‹ä¸€',
    'æ¨ªå±±æ­¦': 'æ¨ªå±±æ­¦å²',
    'æ¾æœ¬': 'æ¾æœ¬å¤§è¼',
    'ä¸¹å†…': 'ä¸¹å†…ç¥æ¬¡',
    'å¤§é‡': 'å¤§é‡æ‹“å¼¥',
    'è¥¿æ‘æ·³': 'è¥¿æ‘æ·³ä¹Ÿ'
}

def parse_arima_data(file_path):
    """arima.txtã‚’è§£æã—ã¦å‡ºèµ°é¦¬ãƒªã‚¹ãƒˆã‚’ä½œæˆ"""
    print("=" * 100)
    print("ğŸ“‹ å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    print("=" * 100)

    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    horses = []
    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # æ ç•ªãƒ»é¦¬ç•ªã®è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
        if re.match(r'^\d+\s+\d+', line) or line == '--' or line == 'ç·¨é›†':
            i += 1
            continue

        # é¦¬åã®è¡Œ
        if line and not re.match(r'^[ç‰¡ç‰ã‚»]\d+', line):
            horse_name = line
            i += 1

            # æ¬¡ã®è¡Œã«è©³ç´°æƒ…å ±
            if i < len(lines):
                details = lines[i].strip()
                parts = details.split('\t')

                if len(parts) >= 7:
                    sex_age = parts[0]
                    weight = float(parts[1]) if parts[1] else 0
                    jockey = parts[2]
                    odds = float(parts[5]) if parts[5] else 0
                    popularity = int(parts[6]) if parts[6] else 0

                    # æ€§åˆ¥ã¨å¹´é½¢ã‚’åˆ†é›¢
                    if sex_age:
                        sex = 1 if sex_age[0] == 'ç‰¡' else (2 if sex_age[0] == 'ç‰' else 3)
                        age = int(sex_age[1]) if len(sex_age) > 1 and sex_age[1].isdigit() else 0
                    else:
                        sex = 0
                        age = 0

                    # é¨æ‰‹åã‚’æ­£è¦åŒ–
                    normalized_jockey = JOCKEY_MAPPING.get(jockey, jockey)

                    horses.append({
                        'horse_name': horse_name,
                        'sex': sex,
                        'age': age,
                        'jockey_weight': weight,
                        'jockey_name_arima': jockey,  # arima.txtã®è¡¨è¨˜
                        'jockey_name_normalized': normalized_jockey,  # æ­£è¦åŒ–å¾Œ
                        'odds': odds,
                        'popularity': popularity
                    })
            i += 1
        else:
            i += 1

    df = pd.DataFrame(horses)

    print(f"\nâœ… {len(df)}é ­ã®å‡ºèµ°é¦¬ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    print("\nã€å‡ºèµ°é¦¬ä¸€è¦§ã€‘")
    for idx, row in df.iterrows():
        print(f"  {idx+1:2d}. {row['horse_name']:20s} | {row['age']}æ­³ | {row['jockey_name_arima']:10s} | {row['popularity']:2d}ç•ªäººæ°— | {row['odds']:6.1f}å€")

    return df

def get_jockey_ids(jockey_names):
    """é¨æ‰‹åã‹ã‚‰jockey_idã‚’å–å¾—"""
    client = bigquery.Client(project=PROJECT_ID)

    print("\n" + "=" * 100)
    print("ğŸ” é¨æ‰‹IDã‚’å–å¾—ä¸­...")
    print("=" * 100)

    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªé¨æ‰‹åãƒªã‚¹ãƒˆ
    unique_jockeys = list(set(jockey_names))

    # WHEREå¥ã‚’æ§‹ç¯‰
    where_conditions = []
    for jockey in unique_jockeys:
        where_conditions.append(f"jockey_name = '{jockey}'")

    where_clause = " OR ".join(where_conditions)

    query = f"""
    SELECT jockey_id, jockey_name, region, debut_year
    FROM `{PROJECT_ID}.{DATASET_ID}.jockey`
    WHERE {where_clause}
    ORDER BY jockey_name
    """

    df = client.query(query).to_dataframe()

    print(f"\nâœ… {len(df)}äººã®é¨æ‰‹IDã‚’å–å¾—")

    # é¨æ‰‹å â†’ jockey_id ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    jockey_id_map = {}
    for idx, row in df.iterrows():
        jockey_id_map[row['jockey_name']] = row['jockey_id']
        print(f"  {row['jockey_name']:15s} â†’ ID: {row['jockey_id']}")

    return jockey_id_map

def get_jockey_stats_by_id(jockey_id_map):
    """jockey_idã‚’ä½¿ã£ã¦é¨æ‰‹ã®èŠ2500mæˆç¸¾ã‚’å–å¾—"""
    client = bigquery.Client(project=PROJECT_ID)

    print("\n" + "=" * 100)
    print("ğŸ‡ é¨æ‰‹æˆç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    print("=" * 100)

    # jockey_idã®ãƒªã‚¹ãƒˆ
    jockey_ids = list(jockey_id_map.values())
    jockey_ids_str = ','.join(map(str, jockey_ids))

    query = f"""
    WITH jockey_stats AS (
      SELECT
        jockey_id,
        jockey_name,
        COUNT(*) as rides,
        AVG(CASE WHEN finish_position <= 3 THEN 1 ELSE 0 END) as place_rate
      FROM `{PROJECT_ID}.{DATASET_ID}.all_features_complete_improved`
      WHERE jockey_id IN ({jockey_ids_str})
        AND surface = 'èŠ'
        AND distance = 2500
        AND race_date >= '2020-01-01'
      GROUP BY jockey_id, jockey_name
      HAVING COUNT(*) >= 1
    )
    SELECT *
    FROM jockey_stats
    ORDER BY rides DESC
    """

    df = client.query(query).to_dataframe()

    print(f"\nâœ… {len(df)}äººã®é¨æ‰‹æˆç¸¾ã‚’å–å¾—")

    # jockey_id â†’ æˆç¸¾ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    jockey_stats_map = {}
    for idx, row in df.iterrows():
        jockey_stats_map[row['jockey_id']] = {
            'jockey_name': row['jockey_name'],
            'rides': row['rides'],
            'place_rate': row['place_rate']
        }
        print(f"  ID {row['jockey_id']:4d} | {row['jockey_name']:15s} | {row['rides']:4.0f}å› | è¤‡å‹ç‡{row['place_rate']*100:5.1f}%")

    return jockey_stats_map

def get_horse_features_from_bigquery(horse_names):
    """BigQueryã‹ã‚‰å‡ºèµ°é¦¬ã®éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    client = bigquery.Client(project=PROJECT_ID)

    print("\n" + "=" * 100)
    print("ğŸ” BigQueryã‹ã‚‰å‡ºèµ°é¦¬ã®éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    print("=" * 100)

    horse_names_sql = "', '".join(horse_names)

    query = f"""
    WITH latest_races AS (
      SELECT
        f.*,
        ROW_NUMBER() OVER (PARTITION BY f.horse_name ORDER BY f.race_date DESC) as rn
      FROM `{PROJECT_ID}.{DATASET_ID}.all_features_complete_improved` f
      WHERE f.horse_name IN ('{horse_names_sql}')
        AND f.race_date < '2025-12-22'
    )
    SELECT *
    FROM latest_races
    WHERE rn = 1
    """

    df = client.query(query).to_dataframe()

    if len(df) == 0:
        print("\nâš ï¸ BigQueryã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None

    print(f"\nâœ… {len(df)}é ­ã®éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")

    return df

def prepare_arima_features(arima_df, past_data_df, jockey_id_map, jockey_stats_map):
    """æœ‰é¦¬è¨˜å¿µç”¨ã®ç‰¹å¾´é‡ã‚’æº–å‚™"""
    print("\n" + "=" * 100)
    print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆæœ‰é¦¬è¨˜å¿µï¼‰")
    print("=" * 100)

    # æœ‰é¦¬è¨˜å¿µã®ãƒ¬ãƒ¼ã‚¹æ¡ä»¶
    ARIMA_RACECOURSE = 'ä¸­å±±'
    ARIMA_SURFACE = 'èŠ'
    ARIMA_DISTANCE = 2500
    ARIMA_GOING = 'è‰¯'
    ARIMA_RACE_CLASS = 'ã‚ªãƒ¼ãƒ—ãƒ³'

    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    racecourse_map = {'æœ­å¹Œ': 1, 'å‡½é¤¨': 2, 'ç¦å³¶': 3, 'æ–°æ½Ÿ': 4, 'æ±äº¬': 5, 'ä¸­å±±': 6, 'ä¸­äº¬': 7, 'äº¬éƒ½': 8, 'é˜ªç¥': 9, 'å°å€‰': 10}
    surface_map = {'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}
    going_map = {'è‰¯': 0, 'ã‚„ã‚„é‡': 1, 'é‡': 2, 'ä¸è‰¯': 3}
    race_class_map = {'æ–°é¦¬': 0, 'æœªå‹åˆ©': 1, 'ï¼‘å‹ã‚¯ãƒ©ã‚¹': 2, 'ï¼’å‹ã‚¯ãƒ©ã‚¹': 3, 'ï¼“å‹ã‚¯ãƒ©ã‚¹': 4, 'ã‚ªãƒ¼ãƒ—ãƒ³': 5}

    features_list = []

    for idx, arima_row in arima_df.iterrows():
        horse_name = arima_row['horse_name']

        # éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©²å½“é¦¬ã‚’æ¤œç´¢
        past_row = past_data_df[past_data_df['horse_name'] == horse_name]

        if len(past_row) == 0:
            print(f"âš ï¸ {horse_name}: éå»ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            continue

        past_row = past_row.iloc[0]

        # é¨æ‰‹IDã¨æˆç¸¾ã‚’å–å¾—
        jockey_name_normalized = arima_row['jockey_name_normalized']
        jockey_id = jockey_id_map.get(jockey_name_normalized, 0)
        jockey_stats = jockey_stats_map.get(jockey_id, {'rides': 0, 'place_rate': 0.25})

        # é¨æ‰‹å¤‰æ›´åˆ¤å®š
        is_jockey_change = 1 if jockey_id != past_row.get('jockey_id', 0) else 0

        # ç‰¹å¾´é‡ã‚’æº–å‚™
        features = {
            # arima.txtã‹ã‚‰
            'horse_name': horse_name,
            'sex': arima_row['sex'],
            'age': arima_row['age'],
            'odds': arima_row['odds'],
            'popularity': arima_row['popularity'],

            # æœ‰é¦¬è¨˜å¿µã®ãƒ¬ãƒ¼ã‚¹æ¡ä»¶
            'racecourse_encoded': racecourse_map.get(ARIMA_RACECOURSE, 0),
            'surface_encoded': surface_map.get(ARIMA_SURFACE, 0),
            'going_encoded': going_map.get(ARIMA_GOING, 0),
            'race_class_encoded': race_class_map.get(ARIMA_RACE_CLASS, 5),
            'distance': ARIMA_DISTANCE,

            # éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰
            'running_style_last1': past_row.get('running_style_last1', 0),
            'running_style_mode': past_row.get('running_style_mode', 0),
            'running_style_mode_win_rate': past_row.get('running_style_mode_win_rate', 0),
            'running_style_last1_win_rate': past_row.get('running_style_last1_win_rate', 0),

            # é¨æ‰‹ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ‰é¦¬è¨˜å¿µã§é¨ä¹—ã™ã‚‹é¨æ‰‹ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
            'jockey_rides_surface_distance': jockey_stats['rides'],
            'jockey_place_rate_surface_distance': jockey_stats['place_rate'],
            'is_jockey_change': is_jockey_change,

            'finish_pos_best_last5': past_row.get('finish_pos_best_last5', 10),

            'horse_weight': past_row.get('horse_weight', 500),
            'weight_change': 0,
            'bracket_number': idx // 2 + 1,
            'horse_number': idx + 1,
            'days_since_last_race': 30,

            # ã‚¿ã‚¤ãƒ æŒ‡æ•°ï¼ˆæ”¹å–„ç‰ˆï¼‰
            'time_index_zscore_last1_improved': past_row.get('time_index_zscore_last1_improved', 0),
            'time_index_zscore_last2_improved': past_row.get('time_index_zscore_last2_improved', 0),
            'time_index_zscore_last3_improved': past_row.get('time_index_zscore_last3_improved', 0),
            'time_index_zscore_mean_3_improved': past_row.get('time_index_zscore_mean_3_improved', 0),
            'time_index_zscore_best_3_improved': past_row.get('time_index_zscore_best_3_improved', 0),
            'time_index_zscore_worst_3_improved': past_row.get('time_index_zscore_worst_3_improved', 0),
            'time_index_zscore_trend_3_improved': past_row.get('time_index_zscore_trend_3_improved', 0),

            # ãƒ©ã‚¹ãƒˆ3FæŒ‡æ•°
            'last3f_index_zscore_last1_improved': past_row.get('last3f_index_zscore_last1_improved', 0),
            'last3f_index_zscore_last2_improved': past_row.get('last3f_index_zscore_last2_improved', 0),

            # ä¼‘é¤Šé–¢é€£
            'is_after_long_rest': 0,
            'is_consecutive_race': 0,
            'is_debut': 0,
            'rest_period_category': 2
        }

        features_list.append(features)

    features_df = pd.DataFrame(features_list)

    print(f"\nâœ… {len(features_df)}é ­ã®ç‰¹å¾´é‡ã‚’æº–å‚™ã—ã¾ã—ãŸ")

    return features_df

def predict_arima(features_df, model_path):
    """æœ‰é¦¬è¨˜å¿µã‚’äºˆæ¸¬"""
    print("\n" + "=" * 100)
    print("ğŸ”® æœ‰é¦¬è¨˜å¿µ2025äºˆæ¸¬")
    print("=" * 100)

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    with open(model_path, 'rb') as f:
        model = pickle.load(f)

    # äºˆæ¸¬ç”¨ã®ç‰¹å¾´é‡ã‚’æº–å‚™
    feature_cols = [
        'running_style_last1', 'running_style_mode',
        'running_style_mode_win_rate', 'running_style_last1_win_rate',
        'jockey_rides_surface_distance',
        'jockey_place_rate_surface_distance',
        'is_jockey_change',
        'finish_pos_best_last5',
        'racecourse_encoded', 'surface_encoded', 'going_encoded', 'race_class_encoded',
        'distance', 'sex', 'age', 'horse_weight', 'weight_change',
        'bracket_number', 'horse_number', 'days_since_last_race',
        'time_index_zscore_last1_improved',
        'time_index_zscore_last2_improved',
        'time_index_zscore_last3_improved',
        'time_index_zscore_mean_3_improved',
        'time_index_zscore_best_3_improved',
        'time_index_zscore_worst_3_improved',
        'time_index_zscore_trend_3_improved',
        'last3f_index_zscore_last1_improved',
        'last3f_index_zscore_last2_improved',
        'is_after_long_rest', 'is_consecutive_race', 'is_debut', 'rest_period_category'
    ]

    X = features_df[feature_cols].fillna(0)

    # äºˆæ¸¬
    y_pred = model.predict(X)

    # çµæœã‚’DataFrameã«è¿½åŠ 
    features_df['win_probability'] = y_pred
    features_df['predicted_rank'] = features_df['win_probability'].rank(ascending=False, method='first').astype(int)

    # ã‚½ãƒ¼ãƒˆ
    result_df = features_df.sort_values('predicted_rank')

    # çµæœè¡¨ç¤º
    print("\nã€äºˆæ¸¬çµæœã€‘")
    print("=" * 100)
    print(f"{'äºˆæ¸¬é †ä½':>8} {'é¦¬å':20} {'å¹´é½¢':>4} {'äººæ°—':>4} {'ã‚ªãƒƒã‚º':>8} {'å‹ç‡':>8} {'ã‚¿ã‚¤ãƒ æŒ‡æ•°':>10}")
    print("-" * 100)

    for idx, row in result_df.iterrows():
        print(f"{row['predicted_rank']:>8.0f} {row['horse_name']:20} {row['age']:>4.0f}æ­³ {row['popularity']:>4.0f}ç•ª {row['odds']:>8.1f}å€ {row['win_probability']*100:>7.2f}% {row['time_index_zscore_last1_improved']:>10.2f}")

    # ä¸Šä½3é ­ã‚’å¼·èª¿è¡¨ç¤º
    print("\n" + "=" * 100)
    print("ğŸ† äºˆæ¸¬ä¸Šä½3é ­")
    print("=" * 100)

    for i in range(min(3, len(result_df))):
        row = result_df.iloc[i]
        print(f"\n{i+1}ä½: {row['horse_name']}")
        print(f"  å‹ç‡: {row['win_probability']*100:.2f}%")
        print(f"  äººæ°—: {row['popularity']:.0f}ç•ªäººæ°—")
        print(f"  ã‚ªãƒƒã‚º: {row['odds']:.1f}å€")
        print(f"  ã‚¿ã‚¤ãƒ æŒ‡æ•°ï¼ˆå‰èµ°ï¼‰: {row['time_index_zscore_last1_improved']:.2f}")
        print(f"  ã‚¿ã‚¤ãƒ æŒ‡æ•°ï¼ˆ3èµ°å¹³å‡ï¼‰: {row['time_index_zscore_mean_3_improved']:.2f}")

    # CSVä¿å­˜
    result_df[['predicted_rank', 'horse_name', 'age', 'popularity', 'odds', 'win_probability',
               'time_index_zscore_last1_improved', 'time_index_zscore_mean_3_improved']].to_csv(
        'data/arima_2025_predictions_v2.csv', index=False, encoding='utf-8-sig'
    )

    print("\n" + "=" * 100)
    print("ğŸ’¾ äºˆæ¸¬çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: data/arima_2025_predictions_v2.csv")
    print("=" * 100)

    return result_df

def main():
    print("\n" + "=" * 100)
    print("ğŸ„ 2025å¹´æœ‰é¦¬è¨˜å¿µäºˆæ¸¬ï¼ˆé¨æ‰‹IDç‰ˆï¼‰")
    print("=" * 100)

    # 1. arima.txtã‚’èª­ã¿è¾¼ã¿
    arima_df = parse_arima_data('/Users/kubotataichi/Desktop/keiba-data-site/arima.txt')

    # 2. é¨æ‰‹IDã‚’å–å¾—
    jockey_id_map = get_jockey_ids(arima_df['jockey_name_normalized'].tolist())

    # 3. é¨æ‰‹ã®æˆç¸¾ã‚’å–å¾—
    jockey_stats_map = get_jockey_stats_by_id(jockey_id_map)

    # 4. BigQueryã‹ã‚‰éå»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    past_data_df = get_horse_features_from_bigquery(arima_df['horse_name'].tolist())

    if past_data_df is None:
        print("\nâŒ éå»ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # 5. ç‰¹å¾´é‡ã‚’æº–å‚™
    features_df = prepare_arima_features(arima_df, past_data_df, jockey_id_map, jockey_stats_map)

    # 6. äºˆæ¸¬
    result_df = predict_arima(features_df, 'model_improved_time_index.pkl')

    print("\n" + "=" * 100)
    print("âœ… ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("=" * 100)

if __name__ == '__main__':
    main()
