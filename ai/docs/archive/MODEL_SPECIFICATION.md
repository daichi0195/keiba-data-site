# 競馬AI予測モデル - 仕様と改善ポイント

## 📊 現在のモデル仕様

### モデルアーキテクチャ

**使用モデル**: LightGBM LambdaRank + Isotonic Regression (確率較正)

```
入力特徴量（25次元）
    ↓
LightGBM LambdaRank（ランキング学習）
    ↓
ソフトマックス（レース内で確率化）
    ↓
Isotonic Regression（確率較正）
    ↓
較正済み勝率予測
    ↓
期待値計算（勝率 × オッズ）
    ↓
購入判定（期待値 ≥ 閾値）
```

### データ期間

| 項目 | 期間 | レース数 | 備考 |
|------|------|----------|------|
| **訓練データ** | 2020/01/05 ～ 2025/08/31 | 18,941 | 約5.7年分 |
| **テストデータ** | 2025/09/06 ～ 2025/10/26 | 486 | 50日間 |

### 入力特徴量（25次元）

#### 1. タイム偏差値関連（8次元）
- `time_dev_last1～5`: 過去5走のタイム偏差値
- `time_dev_mean_5`: 過去5走の平均タイム偏差値
- `time_dev_max_5`: 過去5走の最高タイム偏差値
- `time_dev_trend_5`: タイム偏差値のトレンド（改善傾向）

**計算方法**:
```
タイム偏差値 = (平均タイム - 実測タイム) / 標準偏差
```
- Level 1: コース×馬場×距離ごと（200件以上のサンプル必要）
- Level 2: 馬場×距離帯（1200/1600/2000/2400m）

#### 2. 騎手成績（3次元）
- `jockey_place_rate_surface_distance`: 馬場×距離帯別の複勝率
- `jockey_rides_surface_distance`: 馬場×距離帯別の出走回数
- `is_jockey_change`: 騎手変更フラグ（0 or 1）

#### 3. 馬の成績（2次元）
- `finish_pos_mean_last5`: 過去5走の平均着順
- `finish_pos_best_last5`: 過去5走の最高着順

#### 4. レース条件（4次元）
- `racecourse_encoded`: 競馬場（0-9）
- `surface_encoded`: 馬場（0=芝, 1=ダート）
- `going_encoded`: 馬場状態（0=良, 1=稍重, 2=重, 3=不良）
- `race_class_encoded`: クラス（0=G1, 1=G2, ..., 7=未勝利）

#### 5. 馬の基本情報（7次元）
- `distance`: 距離（メートル）
- `sex`: 性別（1=牡, 2=牝, 3=セ）
- `age`: 年齢
- `horse_weight`: 馬体重
- `weight_change`: 前走からの馬体重変化
- `bracket_number`: 枠番
- `horse_number`: 馬番

#### 6. その他（1次元）
- `days_since_last_race`: 前走からの日数

### モデルパラメータ

```python
{
    'objective': 'lambdarank',
    'metric': 'ndcg',
    'ndcg_eval_at': [1, 3, 5],
    'learning_rate': 0.05,
    'num_leaves': 31,
    'min_data_in_leaf': 20,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'feature_fraction': 0.9,
    'num_iterations': 1000
}
```

### 確率較正

**手法**: Isotonic Regression
- 訓練データで学習した予測確率と実際の勝率の関係を較正
- 単調増加関数でマッピング
- out_of_bounds='clip'（範囲外は0-1にクリップ）

### 推奨購入戦略

```
条件1: オッズ ≤ 30倍
条件2: 期待値 ≥ 1.9
条件3: 各レースで期待値最大の馬を1頭選択
購入額: 100円/レース
```

---

## 📈 現在の性能

### 予測精度

| 指標 | 訓練データ | テストデータ |
|------|----------|-------------|
| **Top1精度** | - | **24.7%** |
| データ期間 | 2020/01～2025/08 | 2025/09/06～10/26 |
| レース数 | 18,941 | 486 |

**改善履歴**:
- タイム偏差値バグ修正前: 12.5%
- バグ修正後: **24.7%** (+97%改善)

### 確率予測の精度

**⚠️ 現状未測定 - 追加実装が必要**

以下の指標を追加測定すべき：

| 指標 | 説明 | 目的 |
|------|------|------|
| **LogLoss** | レース内での確率の当たり具合 | 確率モデルの総合評価 |
| **Brier Score** | 確率の二乗誤差 | 較正精度の評価 |
| **Calibration Curve** | 予測確率と実際の勝率の一致度 | 較正の視覚的評価 |
| **ECE** (Expected Calibration Error) | 較正誤差の定量評価 | 較正の数値評価 |

> **重要**: Top1精度が同じでも、確率が正確なモデルの方が期待値計算で有利

### 回収率

| 閾値 | 回収率 | 購入レース | 的中数 | 的中率 | 平均オッズ |
|------|--------|----------|--------|--------|-----------|
| 1.6 | 108.52% | 284回 | 17回 | 5.99% | 19.9倍 |
| 1.8 | 110.14% | 246回 | 15回 | 6.10% | 20.3倍 |
| **1.9** | **113.22%** | 227回 | 13回 | 5.73% | 21.8倍 |
| 2.0 | 110.00% | 210回 | 12回 | 5.71% | 22.0倍 |
| 2.2 | 92.88% | 174回 | 7回 | 4.02% | 22.8倍 |

**最適戦略**（閾値1.9）:
- 回収率: **113.22%**
- 購入頻度: 全レースの47% (227/486)
- 的中率: 5.73%
- 想定利益: 100円購入で平均113円返却

### 実績サマリー

```
✅ タイム偏差値バグ修正: Top1精度 +97%
✅ BigQuery活用: 特徴量計算 6倍高速化（30分→5分）
✅ 確率較正: 回収率 87% → 113% (+26.2ポイント)
```

---

## ⚠️ データリーク・テスト最適化のリスク

**回収率113%という数字が出た場合、まず疑うべき点**

### 1. 騎手成績の集計範囲（未来情報の混入）

**リスク**:
- `jockey_place_rate_surface_distance`等を「全期間でGROUP BY」すると未来情報が混入
- テスト期間の成績が訓練時に見えてしまう

**正しい実装**:
```python
# ❌ 危険：全期間で集計
jockey_stats = df.groupby('jockey_id').agg({'finish_position': ...})

# ✅ 正解：各レース日時点までの成績のみで集計（expanding window）
jockey_stats = df[df['race_date'] < target_date].groupby('jockey_id').agg(...)
```

**チェック方法**:
```python
# テスト期間で、騎手特徴量を以下2パターンで比較
# 1. 2025/08/31までで固定
# 2. 全期間で集計
# → 精度・回収率が大きく変わるならリーク濃厚
```

**現状**: ✅ BigQueryのSQLで各レース時点までの集計を実装済み

### 2. トラックバイアス系特徴量（当日情報のリーク）

**リスク**:
- `track_variant`を「その日の全レース」から作ると未来情報
- 後のレースのタイムを見て予測していることになる

**正しい実装**:
```python
# ❌ 危険：当日の全レース平均
track_variant = df[df['race_date'] == today].mean_time - historical_mean

# ✅ 正解：当日のそれ以前のレースのみ
track_variant = df[(df['race_date'] == today) & (df['race_number'] < current_race)].mean_time - historical_mean
# （朝イチは欠損）
```

**現状**: ⚠️ 未実装（今後追加時に注意）

### 3. 確率較正後の「合計1」問題

**リスク**:
- Isotonic Regressionは各馬を単調変換するため、レース内合計が1にならない
- 期待値計算が不正確になる可能性

**対策（2択）**:
```python
# オプション1: 較正後に再正規化
probs_calibrated = calibrator.transform(probs_original)
probs_calibrated = probs_calibrated / probs_calibrated.sum()  # レース内で再正規化

# オプション2: softmax前のスコアを較正（解釈は難しくなる）
scores_calibrated = calibrator.transform(scores)
probs = softmax(scores_calibrated)
```

**現状**: ⚠️ 再正規化なし（合計1が保証されていない）

### 4. 購入閾値のテスト最適化

**リスク**:
- 閾値1.9を**テスト期間で選んでいる**場合、テストに過適合
- 実運用では性能が落ちる

**正しい実装**:
```
Train期間（～2025/08）を分割:
  訓練: 2020/01 ～ 2025/03
  検証: 2025/04 ～ 2025/08  ← ここで閾値を決定

固定した閾値で評価:
  テスト: 2025/09 ～ 2025/10  ← 閾値は触らない
```

**現状**: ❌ **テスト期間で閾値を最適化している**（要改善）

### データリーク総合チェックリスト

- [x] タイム偏差値: 各レース時点までのデータのみ使用
- [x] 騎手成績: 各レース時点までの成績のみ使用
- [ ] トラックバイアス: 未実装（実装時に注意）
- [ ] 確率の合計1: 再正規化未実装
- [ ] 閾値選択: テスト期間で最適化（検証期間での選択に変更すべき）

---

## 🔧 改善ポイント

### 優先度：S（最重要・即効性あり）

#### 0. データリーク対策（最優先） ⚠️

**現状の問題**:
- 購入閾値をテスト期間で最適化している
- 確率の合計1が保証されていない

**改善案**:
```python
# 1. 訓練期間を分割して閾値を決定
train_period = df[df['race_date'] < '2025-04-01']
validation_period = df[(df['race_date'] >= '2025-04-01') & (df['race_date'] < '2025-09-01')]

# 検証期間で閾値を最適化
best_threshold = optimize_threshold(validation_period)

# テスト期間では閾値を固定して評価のみ
test_period = df[df['race_date'] >= '2025-09-01']
evaluate(test_period, threshold=best_threshold)

# 2. 確率の再正規化
for race_id in race_ids:
    race_probs = probs_calibrated[race_mask]
    probs_calibrated[race_mask] = race_probs / race_probs.sum()
```

**期待効果**: 評価の信頼性向上（数値は下がる可能性あり、正確な評価）

#### 1. タイム偏差値の階層的スムージング ⭐⭐⭐

**現状の問題**:
- コース×馬場×距離の組み合わせで200件以上ないと計算できない
- 稀少条件（新潟芝外2400m等）では計算不能
- 段階的フォールバックだとレア条件でブレやすい

**改善案**（階層的スムージング）:
```python
# 段階的フォールバックではなく、階層的に「足し合わせ」で推定
time_deviation = (
    grand_mean +  # 全レースの平均
    surface_effect[surface] +  # 馬場の効果
    course_effect[course] +  # コースの効果
    distance_effect[distance_range] +  # 距離帯の効果
    course_surface_interaction[course, surface] +  # 交互作用
    # ...
)

# 各効果はリッジ回帰やベイズで推定
# データが少ない条件ほど、上位階層の効果に縮小（partial pooling）
```

**実装のポイント**:
- 単純な線形/リッジ回帰で実装可能（ベイズにしなくてもOK）
- レア条件でも「コース効果」「馬場効果」から推定可能
- データ量に応じて自動的にスムージング強度が変わる

**期待効果**: Top1精度 +2～5%、レア条件での安定性向上

#### 2. ペース指標の追加 ⭐⭐⭐

**現状の問題**:
- タイム偏差値のみでペース配分を考慮できていない
- 逃げ・先行馬が有利なスローペースを予測できない
- 展開（ペース）による有利不利を予測できない

**追加特徴量**:
```python
# 過去の実績
- last_3f_deviation_last1~5: 過去5走の上がり3F偏差値
- last_3f_mean: 過去5走の平均上がり3F偏差値
- pace_type_last1~5: 過去5走のペースタイプ（スロー/ミドル/ハイ）
- running_style_encoded: 脚質（0=逃げ, 1=先行, 2=差し, 3=追込）

# 今回条件との相性
- distance_change: 前走との距離差
- last_3f_vs_distance: 上がり適性と今回距離の相性
  # 例: 上がりが速い馬 × 長距離 = 相性悪い
```

**実装のコツ**（レビューより）:
- 「過去N走の平均」と「今回条件との差」の両方を持つ
- 例: 前走上がり偏差値、過去5走平均、今回距離帯との相性

**期待効果**: Top1精度 +3～7%, 回収率 +5～10%

### 優先度：A（効果大だがリーク注意）

#### 3. 馬場差・トラックバイアスの考慮 ⭐⭐

**現状の問題**:
- 同じ「中山ダート1800m 良」でも、開催日ごとに馬場の固さが異なる
- 内枠有利・外枠有利などのバイアスを考慮できていない

**追加特徴量**:
```python
# track_variant: 当日の馬場差
# 当日のそれ以前のレースのみから算出（未来情報を含まない）
track_variant = (
    df[(df['race_date'] == today) &
       (df['race_number'] < current_race) &
       (df['surface'] == current_surface) &
       (df['distance_range'] == current_distance_range)]
    .mean_time - historical_mean
)

# データがない場合（朝イチ等）は直近k開催日の平均を使用
if len(earlier_races) == 0:
    track_variant = recent_k_days_average

# bracket_bias: 枠順バイアス（同様に当日それ以前のレースのみ）
```

**⚠️ リーク回避ルール（必須）**:
- 当日の「それ以前」のレースのみ使用
- 同じレース番号以降のデータは絶対に使わない
- 朝イチは欠損値または直近開催日の平均で代替

**期待効果**: 回収率 +2～5%

---

### 優先度：中

#### 4. 血統情報の追加 ⭐⭐

**追加特徴量**:
- `sire_turf_win_rate`: 父の芝勝率
- `sire_dirt_win_rate`: 父のダート勝率
- `sire_distance_aptitude`: 父の距離適性（短距離/マイル/中距離/長距離）
- `dam_sire_encoded`: 母父ID（エンコード済み）

**期待効果**: Top1精度 +1～3%

#### 5. クラス別モデル（分けすぎ注意） ⭐⭐

**現状の問題**:
- G1レースと未勝利戦では傾向が大きく異なる
- 単一モデルで全クラスを予測している

**⚠️ 分けすぎのリスク**:
- モデルを分けるとデータが薄くなる
- 係数（木構造）が不安定になる
- 回収率がブレやすくなる

**推奨アプローチ（レビューより）**:
```python
# ❌ 避けるべき：モデルを分けすぎ
models = {
    'G1': model_g1,      # データが少なすぎて不安定
    'G2': model_g2,      # ...
    'G3': model_g3,
    # ...
}

# ✅ 推奨：race_class_encodedを活かしつつ相互作用を学習
# 単一モデルでOK、GBDTが自動的にクラス別の傾向を学習
features = [
    'race_class_encoded',
    'time_dev_last1',
    # ...
]
# LightGBMが自動的にクラス×特徴量の相互作用を学習

# ✅ 許容範囲：大きく分ける（データが十分あれば）
models = {
    'graded': model_graded,      # G1-G3（データ豊富）
    'open_listed': model_open,   # OP-L（データ中程度）
    'lower': model_lower         # 1-2win-未勝利（データ豊富）
}
```

**実装のポイント**:
- まずは単一モデルで `race_class_encoded` を特徴量として使用
- GBDTは自然にクラス別の傾向を学習する
- モデル分割は最後の手段（効果が見込める場合のみ）

**期待効果**: Top1精度 +1～3%（単一モデル+相互作用で十分な可能性）

#### 6. 長期間でのテスト ⭐⭐

**現状の問題**:
- テスト期間が50日間（486レース）と短い
- 季節性やコース替わりの影響を評価できない

**改善案**:
- テスト期間: 最低3ヶ月～半年
- 季節別の評価（春競馬、夏競馬、秋競馬、冬競馬）
- コース別の評価（中山、東京、阪神、京都等）

**期待効果**: モデルの安定性評価

---

### 優先度：低

#### 7. アンサンブル学習 ⭐

**改善案**:
```python
# 複数モデルの平均
models = [
    LightGBM_LambdaRank,
    XGBoost_Ranker,
    CatBoost_Ranker
]
final_pred = np.mean([m.predict(X) for m in models], axis=0)
```

**期待効果**: Top1精度 +1～2%

#### 8. ニューラルネットワーク ⭐

**改善案**:
- TabNet, FT-Transformer等のディープラーニングモデル
- 特徴量の自動抽出

**期待効果**: Top1精度 +2～5%（ただし計算コスト増）

#### 9. 過去レースの詳細情報 ⭐

**追加特徴量**:
- `last_race_pace`: 前走のペース
- `last_race_going_diff`: 前走と今回の馬場状態の違い
- `last_race_distance_diff`: 前走と今回の距離差

**期待効果**: Top1精度 +1～2%

---

## 🎯 推奨する次のステップ（レビュー後改訂版）

### ⚠️ フェーズ0: データリーク・評価の信頼性確保（最優先）

**回収率113%の信頼性を確保するため、まずこれを実施**:

1. **閾値選択の修正**
   - 訓練期間を Train (～2025/03) + Validation (2025/04～08) に分割
   - Validation期間で閾値を決定
   - Test期間では閾値を固定して評価のみ
   - ✅ 実装後、回収率は下がる可能性あり（それが正しい評価）

2. **確率の再正規化**
   - Isotonic Regression後にレース内で合計1に正規化
   - 期待値計算の精度向上

3. **評価指標の追加**
   - LogLoss（確率の当たり具合）
   - Brier Score（確率の二乗誤差）
   - Calibration Curve（較正の視覚化）
   - ECE（較正誤差）

4. **データリークの最終確認**
   - 騎手成績：各レース時点までのデータのみ使用
   - タイム偏差値：同上
   - （将来追加時）トラックバイアント：当日それ以前のレースのみ

**目標**: 評価の信頼性100%確保（数値は現状維持or下がる可能性）

**⏱ 実装時間**: 2～3日

---

### フェーズ1: 即効性のある改善（1週間）

**評価が信頼できることを確認してから実施**:

1. **タイム偏差値の階層的スムージング** ⭐⭐⭐
   - 段階フォールバックから階層分解へ
   - リッジ回帰で `grand_mean + surface_effect + course_effect + ...` を推定
   - レア条件でも安定した推定

2. **ペース指標の追加** ⭐⭐⭐
   - 上がり3F偏差値（過去5走分）
   - 脚質エンコード（逃げ/先行/差し/追込）
   - 過去平均と今回条件との差分

**目標**: Top1精度 27～30%, 回収率 115～120%（正しい評価での目標）

**⏱ 実装時間**: 5～7日

---

### フェーズ2: 中期的改善（2週間）

3. **トラックバイアスの考慮** ⭐⭐
   - **必須**: 当日それ以前のレースのみ使用（リーク防止）
   - track_variant（馬場差）
   - bracket_bias（枠順バイアス）

4. **血統情報の追加** ⭐
   - 父・母父の成績
   - 距離適性・馬場適性

5. **長期テスト期間での検証** ⭐⭐
   - テスト期間: 3ヶ月～半年
   - 季節別・コース別の評価

**目標**: Top1精度 28～32%, 回収率 120～125%

**⏱ 実装時間**: 10～14日

---

### フェーズ3: 高度な改善（1ヶ月～）

6. **クラス別の特徴量相互作用**
   - まずは単一モデルで `race_class_encoded` × 主要特徴量の相互作用
   - 効果が見込める場合のみモデル分割を検討

7. **アンサンブル学習**
   - 複数モデルの平均（LightGBM + XGBoost + CatBoost）

**目標**: Top1精度 30～35%, 回収率 125～130%

**⏱ 実装時間**: 1ヶ月～

---

### 📋 実装の優先順位まとめ

| 優先度 | 項目 | 期待効果 | リスク | 実装難易度 |
|--------|------|----------|--------|-----------|
| **S（最優先）** | データリーク対策・評価修正 | 信頼性確保 | 低 | 低 |
| **S** | タイム偏差値の階層的スムージング | 精度+3～5% | 低 | 中 |
| **S** | ペース指標（上がり・脚質） | 精度+3～7% | 低 | 低 |
| **A** | トラックバイアス（リーク注意） | 回収率+2～5% | **中（実装ミスでリーク）** | 中 |
| **A** | 血統情報 | 精度+1～3% | 低 | 低 |
| **中** | 長期テスト | 安定性評価 | 低 | 低 |
| **中** | クラス別相互作用 | 精度+1～3% | 中（データ分散） | 中 |
| **低** | アンサンブル学習 | 精度+1～2% | 低 | 中 |

---

## 📝 技術的な制約と課題

### データ品質

- ❌ 2020年以前のデータが限定的
- ❌ 地方競馬のデータなし
- ❌ 調教データ・厩舎コメントなし
- ✅ 中央競馬の基本データは充実

### 計算コスト

- ✅ BigQuery活用で特徴量計算は高速（5分）
- ✅ モデル訓練は10分程度
- ⚠️ ニューラルネット導入時は計算時間増加

### 予測の難しさ

**競馬の本質的な難しさ**:
- ランダム性が高い（実力差が小さい）
- 人気馬でも的中率は30%程度が上限
- 荒れるレースが一定数存在

**現実的な目標**:
- Top1精度: 30～35%（人気1番の的中率と同等以上）
- 回収率: 120～130%（安定して黒字）

---

## 📚 参考文献・関連技術

### 使用技術

- **LightGBM**: Microsoft開発の勾配ブースティング
- **LambdaRank**: ランキング学習の代表的手法
- **Isotonic Regression**: 単調回帰による確率較正
- **BigQuery**: Google Cloudのデータウェアハウス

### 参考論文

1. Burges, C. (2010). "From RankNet to LambdaRank to LambdaMART"
2. Niculescu-Mizil, A. & Caruana, R. (2005). "Predicting Good Probabilities With Supervised Learning"
3. Ke, G. et al. (2017). "LightGBM: A Highly Efficient Gradient Boosting Decision Tree"

---

## 💡 レビューからの重要な教訓

### 回収率113%を見たらまず疑うべきこと（優先順位順）

1. **データリーク（未来情報混入）** ← 最重要
   - 騎手成績：テスト期間の成績が訓練時に見えていないか？
   - トラックバイアス：当日の後のレースのタイムを使っていないか？
   - 確認方法：特徴量を「過去のみ」と「全期間」で比較し、精度が大きく変わるならリーク濃厚

2. **テスト最適化（過適合）**
   - 閾値をテスト期間で選んでいないか？
   - 正解：訓練期間を分割し、検証期間で閾値を決定

3. **確率の妥当性**
   - 較正後の確率がレース内で合計1になっているか？
   - LogLoss / Brier Scoreは測定しているか？

4. **評価期間の短さ**
   - 50日間（486レース）は短い
   - 最低3ヶ月、できれば半年以上でテスト

### 効果が出やすい改善（実装で事故らない形）

#### ✅ 優先度S（すぐやるべき）

1. **タイム偏差値の階層的スムージング**
   - 段階的フォールバックより「足し合わせ」で推定
   - リッジ回帰で `grand_mean + surface_effect + course_effect + ...`
   - レア条件でもブレにくい

2. **ペース指標（上がり・脚質）**
   - タイム偏差値の弱点（展開）を埋める
   - 「過去N走の平均」と「今回条件との差」の両方を持つ

#### ⚠️ 優先度A（効果大だがリスクあり）

3. **トラックバイアス**
   - 強いが、作り方で簡単にリークする
   - **必須ルール**: 当日それ以前のレースのみ使用

#### 🤔 優先度中（効果は限定的 or リスクあり）

4. **クラス別モデル**
   - 分けすぎるとデータが薄くなり不安定
   - まずは単一モデルで `race_class_encoded` × 特徴量の相互作用
   - GBDTなら自然に学習される

### 実装の鉄則（事故防止）

1. **特徴量計算は必ず「各レース時点まで」で実施**
   ```python
   # ❌ 危険
   stats = df.groupby('jockey_id').agg(...)

   # ✅ 安全
   stats = df[df['race_date'] < target_date].groupby('jockey_id').agg(...)
   ```

2. **閾値は検証期間で決定、テスト期間では触らない**
   ```python
   # Train: 訓練
   # Validation: 閾値決定
   # Test: 評価のみ（閾値固定）
   ```

3. **確率モデルなら、確率の評価指標を必ず測定**
   - Top1精度だけでは不十分
   - LogLoss / Brier Score / Calibration Curve

4. **トラックバイアスは「当日それ以前のレースのみ」が鉄則**
   - 実装ルールを最初に決めないと、数字が簡単に盛れる

### 現実的な目標値

| 指標 | 現状 | 短期目標 | 中期目標 | 備考 |
|------|------|---------|---------|------|
| Top1精度 | 24.7% | 27～30% | 30～35% | 人気1番の的中率と同等以上 |
| 回収率 | 113.22%* | 110～115% | 120～125% | *評価方法修正後は下がる可能性 |
| LogLoss | 未測定 | < 2.0 | < 1.8 | 確率モデルの基本評価 |

**重要**: 評価方法を正しく修正すると、回収率は下がる可能性が高い。それが正しい評価。

---

**最終更新**: 2025年12月26日
**バージョン**: 2.0（エキスパートレビュー反映版）
