#!/bin/bash
# BigQueryã§ç‰¹å¾´é‡ã‚’è¨ˆç®—

set -e

PROJECT_ID="umadata"
DATASET="keiba_ai"

echo "========================================="
echo "BigQueryã§ç‰¹å¾´é‡è¨ˆç®—"
echo "========================================="

# SQLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œ
echo "ğŸš€ ç‰¹å¾´é‡è¨ˆç®—ã‚’é–‹å§‹..."
echo ""

bq query \
  --use_legacy_sql=false \
  --project_id=$PROJECT_ID \
  < ai/feature_engineering.sql

echo ""
echo "âœ… BigQueryã§ã®è¨ˆç®—å®Œäº†"

# çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
echo ""
echo "ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."

# Train ãƒ‡ãƒ¼ã‚¿
echo "  â†’ train_features.csv"
bq extract \
  --destination_format=CSV \
  --print_header=true \
  $DATASET.all_features \
  gs://${PROJECT_ID}-temp/train_features_*.csv

# GCSã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
gsutil -m cp "gs://${PROJECT_ID}-temp/train_features_*.csv" /tmp/
cat /tmp/train_features_*.csv > ai/data/train_features.csv
rm /tmp/train_features_*.csv

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
echo "  â†’ ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ä¸­..."
python3 -c "
import pandas as pd

df = pd.read_csv('ai/data/train_features.csv')

# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
categorical_cols = ['racecourse', 'surface', 'going', 'race_class']
for col in categorical_cols:
    df[f'{col}_encoded'] = df[col].astype('category').cat.codes

# æ—¥ä»˜ã§åˆ†å‰²
train_df = df[df['race_date'] <= '2025-08-31'].copy()
test_df = df[(df['race_date'] >= '2025-09-01') & (df['race_date'] <= '2025-10-31')].copy()

# ä¿å­˜
train_df.to_csv('ai/data/train_features.csv', index=False)
test_df.to_csv('ai/data/test_features.csv', index=False)

print(f'å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(train_df):,} è¡Œ')
print(f'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_df):,} è¡Œ')
"

echo ""
echo "========================================="
echo "å®Œäº†ï¼"
echo "========================================="
echo ""
echo "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
echo "  cd ai && python3 train_model.py"
