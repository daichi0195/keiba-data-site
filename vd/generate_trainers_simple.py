#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èª¿æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ BigQuery ã‹ã‚‰å–å¾—ã—ã¦ GCS ã«ä¿å­˜ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰
"""

from google.cloud import bigquery, storage
import json
import sys
from datetime import datetime

# è¨­å®š
PROJECT_ID = 'umadata'
BUCKET_NAME = 'umadata'
DATASET = 'umadata.keiba_data'

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ç¾åœ¨å‡¦ç†ä¸­ã®èª¿æ•™å¸«æƒ…å ±ã‚’ä¿æŒ
TRAINER_ID = None


def get_trainer_basic_info(client):
    """èª¿æ•™å¸«ã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—"""
    query = f"""
    SELECT
      trainer_id,
      trainer_name as name,
      region as stable,
      debut_year,
      is_active
    FROM
      `{DATASET}.trainer`
    WHERE
      trainer_id = {TRAINER_ID}
    """

    try:
        results = client.query(query).result()
        rows = list(results)
        if not rows:
            return None
        return dict(rows[0])
    except Exception as e:
        print(f"   âš ï¸  Error fetching trainer basic info: {str(e)}", file=sys.stderr)
        raise


def get_total_stats(client):
    """ç·åˆæˆç¸¾ã‚’å–å¾—ï¼ˆéå»3å¹´é–“ï¼‰"""
    query = f"""
    SELECT
      COUNT(*) as races,
      SUM(CASE WHEN rr.finish_position = 1 THEN 1 ELSE 0 END) as wins,
      SUM(CASE WHEN rr.finish_position = 2 THEN 1 ELSE 0 END) as places_2,
      SUM(CASE WHEN rr.finish_position = 3 THEN 1 ELSE 0 END) as places_3,
      ROUND(AVG(CASE WHEN rr.finish_position = 1 THEN 1 ELSE 0 END) * 100, 1) as win_rate,
      ROUND(AVG(CASE WHEN rr.finish_position <= 2 THEN 1 ELSE 0 END) * 100, 1) as quinella_rate,
      ROUND(AVG(CASE WHEN rr.finish_position <= 3 THEN 1 ELSE 0 END) * 100, 1) as place_rate
    FROM
      `{DATASET}.race_master` rm
      JOIN `{DATASET}.race_result` rr ON rm.race_id = rr.race_id
    WHERE
      CAST(rr.trainer_id AS STRING) = CAST({TRAINER_ID} AS STRING)
      AND rm.race_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 3 YEAR)
    """

    try:
        results = client.query(query).result()
        rows = list(results)
        if not rows:
            return None
        return dict(rows[0])
    except Exception as e:
        print(f"   âš ï¸  Error fetching total stats: {str(e)}", file=sys.stderr)
        raise


def process_trainer(bq_client, storage_client, trainer_id, trainer_name):
    """1äººã®èª¿æ•™å¸«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã¦GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    global TRAINER_ID
    TRAINER_ID = trainer_id

    print(f"\n{'='*60}")
    print(f"ğŸ“Š Processing: {trainer_name} (ID: {trainer_id})")
    print(f"{'='*60}")

    try:
        # åŸºæœ¬æƒ…å ±ã‚’å–å¾—
        print("  [1/2] Fetching basic info...")
        basic_info = get_trainer_basic_info(bq_client)
        if not basic_info:
            print(f"  âš ï¸  Trainer not found: {trainer_id}")
            return False

        print("  [2/2] Fetching total stats...")
        total_stats = get_total_stats(bq_client)

        # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã¨æ›´æ–°æ—¥ã‚’è¨­å®š
        today = datetime.now()
        yesterday = datetime(today.year, today.month, today.day - 1) if today.day > 1 else datetime(today.year, today.month - 1, 28)
        three_years_ago = datetime(yesterday.year - 3, yesterday.month, yesterday.day)

        data_period = f"ç›´è¿‘3å¹´é–“åˆ†ï¼ˆ{three_years_ago.year}å¹´{three_years_ago.month}æœˆ{three_years_ago.day}æ—¥ã€œ{yesterday.year}å¹´{yesterday.month}æœˆ{yesterday.day}æ—¥ï¼‰"
        last_updated = f"{today.year}å¹´{today.month}æœˆ{today.day}æ—¥"

        # JSONãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ï¼ˆæœ€å°é™ï¼‰
        trainer_data = {
            'id': str(trainer_id).zfill(5),
            'name': basic_info['name'],
            'kana': 'ã‚„ã¯ãã‚ˆã—ã¨',  # ãƒ†ã‚¹ãƒˆç”¨ã«å›ºå®š
            'stable': basic_info['stable'] or '',
            'debut_year': basic_info['debut_year'],
            'data_period': data_period,
            'last_updated': last_updated,
            'total_races': total_stats['races'] if total_stats else 0,
            'total_stats': total_stats or {},
            'yearly_leading': [],
            'yearly_stats': [],
            'distance_stats': [],
            'surface_stats': [],
            'popularity_stats': {},
            'running_style_stats': [],
            'gate_stats': [],
            'course_stats': [],
            'jockey_stats': [],
            'class_stats': [],
            'track_condition_stats': [],
            'gender_stats': [],
            'racecourse_stats': [],
            'owner_stats': [],
        }

        # GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        bucket = storage_client.bucket(BUCKET_NAME)
        blob_path = f'trainer/{str(trainer_id).zfill(5)}.json'
        blob = bucket.blob(blob_path)
        blob.upload_from_string(
            json.dumps(trainer_data, ensure_ascii=False, indent=2),
            content_type='application/json'
        )

        print(f"  âœ… {trainer_name} uploaded to {blob_path}")
        return True

    except Exception as e:
        print(f"  âŒ Error processing {trainer_name}: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description='Export trainer data from BigQuery to GCS')
    parser.add_argument('--trainer-id', type=int, required=True, help='Process a specific trainer by ID')
    args = parser.parse_args()

    try:
        # BigQueryã¨GCS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        bq_client = bigquery.Client(project=PROJECT_ID)
        storage_client = storage.Client(project=PROJECT_ID)

        print(f"ğŸš€ Starting trainer data export (TEST MODE)")
        print(f"   Processing trainer ID: {args.trainer_id}")
        success = process_trainer(bq_client, storage_client, args.trainer_id, f"ID:{args.trainer_id}")

        print(f"\n{'='*60}")
        if success:
            print(f"âœ… Processing complete!")
        else:
            print(f"âŒ Processing failed!")
        print(f"{'='*60}")

    except Exception as e:
        print(f"âŒ Fatal error: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
